### Experiments Run 06-13-23 and 06-14-23
**ARCHITECTURE:** All the following experiments used the same GRU encoder-decoder architecture. The encoder consisted of an embedding layer (embedding dimension 32) and a single [PyTorch GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html) (hidden dimension 32). The final output of the GRU was the output of the encoder. The decoder consisted of an embedding layer (embedding dimension 32), followed by a single GRU layer (hidden dimension 32), followed by a linear layer to project the GRU output to a distribution the size of the parsed english vocabulary (in this case, a projection from 32 dimensions to 45 dimensions). The output of the decoder was thus the logits for the next likely word in the parsed output.
**TRAINING:** The initial input to the decoder was always special "\<START\>" character. For all future inputs to the decoder, we adopted a teacher forcing training method with a ratio of 0.5. We used [cross entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) for the loss function, which allowed us to use the logit outputs of the model directly. The optimizer for both the encoder and the decoder was [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) with default settings. For all models trained in this experiment, we trained over the shuffled data for 15 epochs with a batch size of 32. For the results below, we trained each model in this way 20 times to get accurate confidence intervals.
**EXPERIMENTS** The first experiment we ran was letting the training set be all sentences except those of the form "WITHHELD-NAME VERB herself" for all WITHHELD-NAMEs from specific sets of female names. We then tested the accuracy of the model on these withheld sentences. The graph to the left below shows the accuracy on the test set for excluding 1, 5, 10, 11, 12, 13, and 14 female names in this way. For the second experiment, we did the same exact test except we removed all sentenes of the form "MALE-NAME VERB himself" from the dataset (both train and test.) Before running the experiment, we hypothesise that:
1. In both experiments, we will see a negative correlation between the number of withheld female names in the training set and the test accuracy on these withheld names
2. We will see generally lower accuracies (and perhaps a sharper decline) in the second experiment. This is because we predict that the model is able to learn that "himself" and "herself" mean basically the same thing, so learning about "himself" helps the model learn about "himself."
<p align="center">
    <img height="500" src="https://github.com/luk27182/Reflexive-Anaphora/blob/main/Figures/Experiment_Results_061423-Removing_Female_Names.png?raw=true" alt="Experiment Results">
    <img height="500" src="https://github.com/luk27182/Reflexive-Anaphora/blob/main/Figures/Experiment_Results_061423-Removing_Female_Names-WITHOUT_HIMSELF.png?raw=true" alt="Experiment Results">
</p>